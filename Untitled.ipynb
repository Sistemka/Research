{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import isfile, join\n",
    "from os import listdir\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras.applications import VGG16\n",
    "\n",
    "import cv2\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import PIL\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Препроцессинг картинок под размер (224 224 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 224\n",
    "height = 224\n",
    "\n",
    "\n",
    "def resize_image(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "    resized = cv2.resize(image, (width, height), interpolation=cv2.INTER_AREA)\n",
    "    return resized\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Картинку в тензор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(image_path):\n",
    "    resized = resize_image(image_path)\n",
    "    return tf.keras.preprocessing.image.img_to_array(img=resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем датесет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(path):\n",
    "    return [f for f in listdir(path) if isfile(join(path, f))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "shirts_path = list_files('files/shirts')\n",
    "\n",
    "shirts = [preproc('/Users/markantipin/Desktop/Systemka/tmp/files/shirts/' + path) for path in shirts_path]\n",
    "\n",
    "boots_path = list_files('files/boots')\n",
    "\n",
    "boots = [preproc('/Users/markantipin/Desktop/Systemka/tmp/files/boots/' + path) for path in boots_path]\n",
    "\n",
    "pants_path = list_files('files/pants')\n",
    "\n",
    "pants = [preproc('/Users/markantipin/Desktop/Systemka/tmp/files/pants/' + path) for path in pants_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_left = shirts * 3 + boots * 3 + pants * 3\n",
    "x_right = boots + pants + shirts + boots + pants + shirts + boots + pants + shirts\n",
    "\n",
    "labels = [0] * 10 + [0] * 10 + [1] * 10 + [1] * 10 + [0] * 10 + [0] * 10 + [0] * 10 + [1] * 10 + [0] * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_left = np.array(x_left)\n",
    "x_right = np.array(x_right)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((90, 224, 224, 3), (90, 224, 224, 3), (90,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_left.shape, x_right.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model2(size):\n",
    "    vgg = VGG16(include_top=False, weights='imagenet', pooling='max', input_shape=(224, 224, 3))\n",
    "    \n",
    "    for layer in vgg.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    input1 = layers.Input(shape=size)\n",
    "    input2 = layers.Input(shape=size)\n",
    "    \n",
    "    vgg_out1 = vgg(input1)\n",
    "    vgg_out2 = vgg(input2)\n",
    "    concat = layers.Concatenate()([vgg_out1, vgg_out2])\n",
    "    dense1 = layers.Dense(256, activation='relu')(concat)\n",
    "    dense2 = layers.Dense(128, activation='relu')(dense1)\n",
    "    dense3 = layers.Dense(64, activation='relu')(dense2)\n",
    "    out = layers.Dense(1, activation='sigmoid')(dense3)\n",
    "    \n",
    "    return Model(inputs=[input1, input2], outputs=[out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model2(size=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 81 samples, validate on 9 samples\n",
      "Epoch 1/10\n",
      "81/81 [==============================] - 17s 212ms/step - loss: 15.4990 - accuracy: 0.5185 - val_loss: 11.7201 - val_accuracy: 0.2222\n",
      "Epoch 2/10\n",
      "81/81 [==============================] - 18s 220ms/step - loss: 5.6578 - accuracy: 0.6296 - val_loss: 13.6589 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "81/81 [==============================] - 18s 222ms/step - loss: 2.0819 - accuracy: 0.7160 - val_loss: 21.5967 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "81/81 [==============================] - 18s 228ms/step - loss: 0.7302 - accuracy: 0.8765 - val_loss: 18.4261 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "81/81 [==============================] - 18s 228ms/step - loss: 0.3341 - accuracy: 0.9136 - val_loss: 19.0006 - val_accuracy: 0.1111\n",
      "Epoch 6/10\n",
      "81/81 [==============================] - 18s 226ms/step - loss: 0.0225 - accuracy: 0.9877 - val_loss: 17.6280 - val_accuracy: 0.1111\n",
      "Epoch 7/10\n",
      "81/81 [==============================] - 18s 225ms/step - loss: 0.0378 - accuracy: 0.9877 - val_loss: 16.4274 - val_accuracy: 0.1111\n",
      "Epoch 8/10\n",
      "81/81 [==============================] - 18s 225ms/step - loss: 0.0388 - accuracy: 0.9753 - val_loss: 20.6818 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "81/81 [==============================] - 18s 225ms/step - loss: 0.3994 - accuracy: 0.9136 - val_loss: 7.8020 - val_accuracy: 0.3333\n",
      "Epoch 10/10\n",
      "81/81 [==============================] - 18s 226ms/step - loss: 0.3411 - accuracy: 0.9136 - val_loss: 39.3727 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x160f48fd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[x_left, x_right], y=labels, batch_size=9, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg16 (Model)                   (None, 512)          14714688    input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1024)         0           vgg16[1][0]                      \n",
      "                                                                 vgg16[2][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          262400      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          32896       dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           8256        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            65          dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 15,018,305\n",
      "Trainable params: 303,617\n",
      "Non-trainable params: 14,714,688\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# тестируем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9996797]]\n"
     ]
    }
   ],
   "source": [
    "# sv_new = '/Users/markantipin/Downloads/a8180b26ea650bc18df6c3cf8ed5d9b9_1221_1607.jpg'\n",
    "boot_new = '/Users/markantipin/Downloads/101.jpeg'\n",
    "boot_new_2 = '/Users/markantipin/Desktop/Systemka/Vectorization/files/arb.jpg'\n",
    "\n",
    "# sv_tensor = np.expand_dims(preproc(sv_new), 0)\n",
    "boot_tensor = np.expand_dims(preproc(boot_new), 0)\n",
    "boot2_tensor = np.expand_dims(preproc(boot_new_2), 0)\n",
    "\n",
    "pred = model.predict([boot2_tensor, boot_tensor])\n",
    "print(pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Это модель без VGG16 не удаляйте пока"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(size):\n",
    "    input1 = layers.Input(shape=size)\n",
    "    input2 = layers.Input(shape=size)\n",
    "    \n",
    "    conv_layer1 = layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu')\n",
    "    conv1 = conv_layer1(input1)\n",
    "    conv2 = conv_layer1(input2)\n",
    "    pool1 = layers.MaxPooling2D()(conv1)\n",
    "    pool2 = layers.MaxPooling2D()(conv2)\n",
    "    \n",
    "    conv_layer2 = layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu')\n",
    "    conv1 = conv_layer2(pool1)\n",
    "    conv2 = conv_layer2(pool2)\n",
    "    pool1 = layers.MaxPooling2D()(conv1)\n",
    "    pool2 = layers.MaxPooling2D()(conv2)\n",
    "    \n",
    "    flat1 = layers.Flatten(name='flat1')(pool1)\n",
    "    flat2 = layers.Flatten(name='flat2')(pool2)\n",
    "    concat = layers.Concatenate()([flat1, flat2])\n",
    "    \n",
    "    dense1 = layers.Dense(512, activation='relu')(concat)\n",
    "    dense2 = layers.Dense(256, activation='relu')(dense1)\n",
    "    dense3 = layers.Dense(128, activation='relu')(dense2)\n",
    "    out = layers.Dense(1, activation='sigmoid')(dense3)\n",
    "    \n",
    "    return Model(inputs=[input1, input2], outputs=[out])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

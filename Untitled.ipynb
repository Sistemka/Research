{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import isfile, join\n",
    "from os import listdir\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras.applications import VGG16\n",
    "\n",
    "import cv2\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import PIL\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Препроцессинг картинок под размер (224 224 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 224\n",
    "height = 224\n",
    "\n",
    "\n",
    "def resize_image(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "    resized = cv2.resize(image, (width, height), interpolation=cv2.INTER_AREA)\n",
    "    return resized\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Картинку в тензор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(image_path):\n",
    "    resized = resize_image(image_path)\n",
    "    return tf.keras.preprocessing.image.img_to_array(img=resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем датесет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(path):\n",
    "    return [f for f in listdir(path) if isfile(join(path, f))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "shirts_path = list_files('files/shirts')\n",
    "\n",
    "shirts = [preproc('/Users/markantipin/Desktop/Systemka/tmp/files/shirts/' + path) for path in shirts_path]\n",
    "\n",
    "boots_path = list_files('files/boots')\n",
    "\n",
    "boots = [preproc('/Users/markantipin/Desktop/Systemka/tmp/files/boots/' + path) for path in boots_path]\n",
    "\n",
    "pants_path = list_files('files/pants')\n",
    "\n",
    "pants = [preproc('/Users/markantipin/Desktop/Systemka/tmp/files/pants/' + path) for path in pants_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_left = shirts * 3 + boots * 3 + pants * 3\n",
    "x_right = boots + pants + shirts + boots + pants + shirts + boots + pants + shirts\n",
    "\n",
    "labels = [0] * 10 + [0] * 10 + [1] * 10 + [1] * 10 + [0] * 10 + [0] * 10 + [0] * 10 + [1] * 10 + [0] * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_left = np.array(x_left)\n",
    "x_right = np.array(x_right)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((90, 224, 224, 3), (90, 224, 224, 3), (90,))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_left.shape, x_right.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model2(size):\n",
    "    vgg = VGG16(include_top=False, weights='imagenet', pooling='max', input_shape=(224, 224, 3))\n",
    "    \n",
    "    for layer in vgg.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    input1 = layers.Input(shape=size)\n",
    "    input2 = layers.Input(shape=size)\n",
    "    \n",
    "    vgg_out1 = vgg(input1)\n",
    "    vgg_out2 = vgg(input2)\n",
    "    concat = layers.Concatenate()([vgg_out1, vgg_out2])\n",
    "    dense1 = layers.Dense(256, activation='relu')(concat)\n",
    "    dense2 = layers.Dense(128, activation='relu')(dense1)\n",
    "    dense3 = layers.Dense(64, activation='relu')(dense2)\n",
    "    out = layers.Dense(1, activation='sigmoid')(dense3)\n",
    "    \n",
    "    return Model(inputs=[input1, input2], outputs=[out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model2(size=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 81 samples, validate on 9 samples\n",
      "Epoch 1/10\n",
      "81/81 [==============================] - 17s 215ms/step - loss: 8.8714 - accuracy: 0.5679 - val_loss: 29.5971 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "81/81 [==============================] - 19s 230ms/step - loss: 2.6729 - accuracy: 0.7160 - val_loss: 18.1453 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "81/81 [==============================] - 19s 235ms/step - loss: 1.6803 - accuracy: 0.7901 - val_loss: 17.8423 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "81/81 [==============================] - 20s 247ms/step - loss: 0.7738 - accuracy: 0.9136 - val_loss: 17.5074 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "81/81 [==============================] - 21s 256ms/step - loss: 0.0301 - accuracy: 0.9877 - val_loss: 15.2591 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "81/81 [==============================] - 19s 236ms/step - loss: 0.2857 - accuracy: 0.9383 - val_loss: 27.6147 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "81/81 [==============================] - 19s 238ms/step - loss: 0.5058 - accuracy: 0.9259 - val_loss: 14.6064 - val_accuracy: 0.1111\n",
      "Epoch 8/10\n",
      "81/81 [==============================] - 19s 234ms/step - loss: 0.3556 - accuracy: 0.9136 - val_loss: 9.0540 - val_accuracy: 0.1111\n",
      "Epoch 9/10\n",
      "81/81 [==============================] - 19s 239ms/step - loss: 0.4589 - accuracy: 0.9383 - val_loss: 37.9665 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "81/81 [==============================] - 20s 242ms/step - loss: 0.5187 - accuracy: 0.9259 - val_loss: 18.9560 - val_accuracy: 0.1111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x173d84fd0>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[x_left, x_right], y=labels, batch_size=9, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_15 (InputLayer)           (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg16 (Model)                   (None, 512)          14714688    input_14[0][0]                   \n",
      "                                                                 input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 1024)         0           vgg16[1][0]                      \n",
      "                                                                 vgg16[2][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 256)          262400      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 128)          32896       dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 64)           8256        dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1)            65          dense_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 15,018,305\n",
      "Trainable params: 303,617\n",
      "Non-trainable params: 14,714,688\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# тестируем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99999917]]\n"
     ]
    }
   ],
   "source": [
    "# sv_new = '/Users/markantipin/Downloads/a8180b26ea650bc18df6c3cf8ed5d9b9_1221_1607.jpg'\n",
    "boot_new = '/Users/markantipin/Downloads/krossovki-nubuk.jpg'\n",
    "boot_new_2 = '/Users/markantipin/Downloads/item_image40107.jpg'\n",
    "\n",
    "# sv_tensor = np.expand_dims(preproc(sv_new), 0)\n",
    "boot_tensor = np.expand_dims(preproc(boot_new), 0)\n",
    "boot2_tensor = np.expand_dims(preproc(boot_new_2), 0)\n",
    "\n",
    "pred = model.predict([boot2_tensor, boot_tensor])\n",
    "print(pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Это модель без VGG16 не удаляйте пока"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(size):\n",
    "    input1 = layers.Input(shape=size)\n",
    "    input2 = layers.Input(shape=size)\n",
    "    \n",
    "    conv_layer1 = layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu')\n",
    "    conv1 = conv_layer1(input1)\n",
    "    conv2 = conv_layer1(input2)\n",
    "    pool1 = layers.MaxPooling2D()(conv1)\n",
    "    pool2 = layers.MaxPooling2D()(conv2)\n",
    "    \n",
    "    conv_layer2 = layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu')\n",
    "    conv1 = conv_layer2(pool1)\n",
    "    conv2 = conv_layer2(pool2)\n",
    "    pool1 = layers.MaxPooling2D()(conv1)\n",
    "    pool2 = layers.MaxPooling2D()(conv2)\n",
    "    \n",
    "    flat1 = layers.Flatten(name='flat1')(pool1)\n",
    "    flat2 = layers.Flatten(name='flat2')(pool2)\n",
    "    concat = layers.Concatenate()([flat1, flat2])\n",
    "    \n",
    "    dense1 = layers.Dense(512, activation='relu')(concat)\n",
    "    dense2 = layers.Dense(256, activation='relu')(dense1)\n",
    "    dense3 = layers.Dense(128, activation='relu')(dense2)\n",
    "    out = layers.Dense(1, activation='sigmoid')(dense3)\n",
    "    \n",
    "    return Model(inputs=[input1, input2], outputs=[out])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
